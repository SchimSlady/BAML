{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File reading/writing\n",
    "df = pd.read_csv(\"data.csv\", delimiter=\";\") \n",
    "\n",
    "#Rename columns\n",
    "df = df.rename(columns={'x': 'y','x2': 'y2'})\n",
    "\n",
    "#Transform Objects into categories\n",
    "df['Survived'] = df['Survived'].astype('category')\n",
    "\n",
    "#Drop unnecessary columns\n",
    "df = df.drop('Name', axis=1)\n",
    "df = df.drop('Ticket', axis=1)\n",
    "\n",
    "#Unify labels\n",
    "df['premium'] = df['premium'].replace({\"1\": True,\"0\": False, \"Yes\": True, \"No\": False }).astype('category') #'bool' auch möglich\n",
    "\n",
    "#Map categories on 1 and 0\n",
    "df ['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "#Ersetze die Cabin Nummer nur mit dem zugehörigen Deck \n",
    "df['Cabin'] = df['Cabin'].str[0]\n",
    "\n",
    "#Groß und Kleinschreibung einheitlich!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encoding for Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check value counts before doing one hot encoding\n",
    "value_count = df['xyz'].value_counts()\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply one-hot encoding to non-numeric columns\n",
    "df = pd.get_dummies(df, columns=non_numeric_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data set into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Dataset along NAs in the classification column\n",
    "training_data = df.dropna(subset=['Classif.Col']) #falls es nicht geht .copy()\n",
    "private_data = df[df['Classif.Col'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat NAs in the training data set (and NAs from private data with info from Training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, locate the columns that have at least one missing value (None, NaN, NaT, and similar).\n",
    "print(df.isna().any())         \n",
    "\n",
    "#Drop NAs for Columns where those are only few values\n",
    "training_data = training_data.dropna(subset=[\"Age\", 'Embarked'])\n",
    "\n",
    "#NAs mit dem Durchschnitt befüllen\n",
    "training_data['Age'] = training_data['Age'].fillna(training_data['Age'].mean())\n",
    "\n",
    "#Fülle NAs in den folgenden Spalten mit dem Median Wert 0.0 auf\n",
    "training_data[['RoomService', 'FoodCourt']] = training_data[['RoomService', 'FoodCourt']].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for imbalance\n",
    "anzahl = training_data['Survived'].value_counts(normalize=False)\n",
    "print(anzahl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_df, test_df = train_test_split(training_data, test_size=0.20, stratify=training_data['Churn'], random_state=2023+2024)\n",
    "\n",
    "# Train a random forest model\n",
    "X_train = train_df.drop(columns=['Churn'])\n",
    "#Alternativ: X = train_df[features] mit features = ['feature1', 'feature2', etc.]\n",
    "y_train = train_df['Churn']\n",
    "\n",
    "# Test Set\n",
    "X_test = test_df.drop(columns=['Churn'])\n",
    "#Alternativ: X = test_df[features] mit features = ['feature1', 'feature2', etc.]\n",
    "y_test = test_df['Churn']\n",
    "\n",
    "#Optional: Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)             # Fit the scaler *only* on the train data\n",
    "X_train = scaler.transform(X_train) # Transform train data\n",
    "X_test = scaler.transform(X_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "train_model = RandomForestClassifier(n_estimators=1000, max_features=3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_fits_accuracy = cross_val_score(train_model, X_train, y_train, cv=4, scoring='accuracy')\n",
    "cv_fits_precision = cross_val_score(train_model, X_train, y_train, cv=4, scoring='precision')\n",
    "cv_fits_recall = cross_val_score(train_model, X_train, y_train, cv=4, scoring='recall')\n",
    "cv_fits_BAC = cross_val_score(train_model, X_train, y_train, cv=4, scoring='balanced_accuracy')\n",
    "\n",
    "\n",
    "print(\"\\nCV-Accuracy:\", np.mean(cv_fits_accuracy))\n",
    "print(\"CV-Precision:\", np.mean(cv_fits_precision))\n",
    "print(\"CV-Recall:\", np.mean(cv_fits_recall))\n",
    "print(\"CV-BAC:\", np.mean(cv_fits_BAC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model\n",
    "train_model.fit(train_df.drop(columns=['Churn']), train_df['Churn']) # oder variablen nutzen x_train und y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Case: Check Variable importance split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance Plot\n",
    "importance_values = train_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importance_values})\n",
    "imp_plot = importance_df.plot(kind='bar', x='Feature', y='Importance', legend=False)\n",
    "imp_plot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model on the private data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on test set (private data)\n",
    "test_predictions = train_model.predict(test_df.drop(columns=['DependentVariable']))\n",
    "print(test_predictions)\n",
    "\n",
    "#Not important\n",
    "test_probabilities = train_model.predict_proba(test_df.drop(columns=['Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the predictions into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test predictions into the private data df into the column 'label'\n",
    "private_data['mag'] = test_predictions\n",
    "\n",
    "# Keep only the 'ID' and 'label' columns\n",
    "result = private_data[['ID', 'mag']]\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    'PassengerId': private_data['ID'],  # Identifiziere Passagiere  \n",
    "    'Survived': test_predictions,  # Modellvorhersagen\n",
    "})\n",
    "\n",
    "# Save the result to a CSV file\n",
    "test_predictions_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(test_df['DependentVariable'], test_predictions['DependentVariable'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# BAC; Accuracy, Precision, Recall on Test Data\n",
    "print(\"Test-BAC:\", balanced_accuracy_score (test_df['Churn'], test_predictions['DependentVariable']))    # import:  from sklearn.metrics import balanced_accuracy_score\n",
    "print(\"Test-Accuracy:\", accuracy_score(test_df['Churn'], test_predictions['DependentVariable']))\n",
    "print(\"Test-Precision:\", precision_score(test_df['Churn'], test_predictions['DependentVariable']))\n",
    "print(\"Test-Recall:\", recall_score(test_df['Churn'], test_predictions['DependentVariable']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
